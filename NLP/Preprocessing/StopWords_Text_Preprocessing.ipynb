{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a8158f-1d7c-4cb3-8a85-39de9a4f422b",
   "metadata": {},
   "source": [
    "# StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11a945c2-e909-4c9a-9c45-1e6c912eb358",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ''' India must stand up to the world. Because I believe that unless India stands up to the world, no one will respect us. Only strength respects strength. We must be strong not only as a military power but also as an economic power. Both must go hand-in-hand. My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material. I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. I see four milestones in my career:\n",
    "\n",
    "Twenty years I spent in ISRO. I was given the opportunity to be the project director for India’s first satellite launch vehicle, SLV3. The one that launched Rohini. These years played a very important role in my life of Scienc. After my ISRO years, I joined DRDO and got a chance to be the part of India’s guided missile program. It was my second bliss when Agni met its mission requirements in 1994.\n",
    "\n",
    "The Dept. of Atomic Energy and DRDO had this tremendous partnership in the recent nuclear tests, on May 11 and 13. This was the third bliss. The joy of participating with my team in these nuclear tests and proving to the world that India can make it, that we are no longer a developing nation but one of them. It made me feel very proud as an Indian. The fact that we have now developed for Agni a re-entry structure, for which we have developed this new material. A very light material called carbon-carbon.\n",
    "\n",
    "One day an orthopedic surgeon from Nizam Institute of Medical Sciences visited my laboratory. He lifted the material and found it so light that he took me to his hospital and showed me his patients. There were these little girls and boys with heavy metallic calipers weighing over three kg. each, dragging their feet around.\n",
    "\n",
    "He said to me : Please remove the pain of my patients. In three weeks, we made these floor reaction Orthosis 300-gram calipers and took them to the orthopedic center. The children didn’t believe their eyes. From dragging around a three kg. load on their legs, they could now move around! Their parents had tears in their eyes. That was my fourth bliss!\n",
    "\n",
    "Why is the media here so negative? Why are we in India so embarrassed to recognise our own strengths, our achievements? We are such a great nation. We have so many amazing success stories but we refuse to acknowledge them. W \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3ff9528-ab7e-4af3-94a5-f41bfe21533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bab2bebf-c62e-4b0b-92d2-9340cb90f1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Anonymous\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccda00fd-bad5-403b-b951-1b0eda78fde3",
   "metadata": {},
   "source": [
    "### what are the stopwords available in english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3824f7aa-e511-4923-9c4b-4b9bcbd732d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stp=stopwords.words('english')\n",
    "stp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebfebbf1-2819-4e12-a200-9c1eff645593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer,WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5c6bbe-80a6-4c70-88d9-768a007c7f01",
   "metadata": {},
   "source": [
    "### Our task is from our corpus we need to create sentences , then from those sentences we need to remove the stopwords , and return those sentences  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c391ee30-87cd-4708-8d4a-cc9ba311f43e",
   "metadata": {},
   "source": [
    "#### To get the sentences we need sent_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "616f2ebb-0014-4b3e-970c-5c22a3225bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0ef254f-4b4b-423a-b3ec-d2538b87946a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' India must stand up to the world.',\n",
       " 'Because I believe that unless India stands up to the world, no one will respect us.',\n",
       " 'Only strength respects strength.',\n",
       " 'We must be strong not only as a military power but also as an economic power.',\n",
       " 'Both must go hand-in-hand.',\n",
       " 'My good fortune was to have worked with three great minds.',\n",
       " 'Dr. Vikram Sarabhai of the Dept.',\n",
       " 'of space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.',\n",
       " 'I was lucky to have worked with all three of them closely and consider this the great opportunity of my life.',\n",
       " 'I see four milestones in my career:\\n\\nTwenty years I spent in ISRO.',\n",
       " 'I was given the opportunity to be the project director for India’s first satellite launch vehicle, SLV3.',\n",
       " 'The one that launched Rohini.',\n",
       " 'These years played a very important role in my life of Scienc.',\n",
       " 'After my ISRO years, I joined DRDO and got a chance to be the part of India’s guided missile program.',\n",
       " 'It was my second bliss when Agni met its mission requirements in 1994.',\n",
       " 'The Dept.',\n",
       " 'of Atomic Energy and DRDO had this tremendous partnership in the recent nuclear tests, on May 11 and 13.',\n",
       " 'This was the third bliss.',\n",
       " 'The joy of participating with my team in these nuclear tests and proving to the world that India can make it, that we are no longer a developing nation but one of them.',\n",
       " 'It made me feel very proud as an Indian.',\n",
       " 'The fact that we have now developed for Agni a re-entry structure, for which we have developed this new material.',\n",
       " 'A very light material called carbon-carbon.',\n",
       " 'One day an orthopedic surgeon from Nizam Institute of Medical Sciences visited my laboratory.',\n",
       " 'He lifted the material and found it so light that he took me to his hospital and showed me his patients.',\n",
       " 'There were these little girls and boys with heavy metallic calipers weighing over three kg.',\n",
       " 'each, dragging their feet around.',\n",
       " 'He said to me : Please remove the pain of my patients.',\n",
       " 'In three weeks, we made these floor reaction Orthosis 300-gram calipers and took them to the orthopedic center.',\n",
       " 'The children didn’t believe their eyes.',\n",
       " 'From dragging around a three kg.',\n",
       " 'load on their legs, they could now move around!',\n",
       " 'Their parents had tears in their eyes.',\n",
       " 'That was my fourth bliss!',\n",
       " 'Why is the media here so negative?',\n",
       " 'Why are we in India so embarrassed to recognise our own strengths, our achievements?',\n",
       " 'We are such a great nation.',\n",
       " 'We have so many amazing success stories but we refuse to acknowledge them.',\n",
       " 'W']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = sent_tokenize(corpus)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9392b196-f8d9-403c-8337-440d632e873b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fcb1e6-7a0d-423a-8208-ee91dd2a8c12",
   "metadata": {},
   "source": [
    "#### next task it to take each word from these sentences and test if it is not a stop word , and return the sentences with only stem words\n",
    "\n",
    "Step 1 -> traverse through each sentence ----------\n",
    "Step 2 -> convert each sentence to words ----------\n",
    "Step 3 -> remove where the words are equal to stopword ----------\n",
    "Step 4 -> do stemming/lemmatization on those words -------------\n",
    "Step 5 -> Create sentences using those lemma which are not stop words -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7abffe3-cde5-46f2-8490-d3e31bc66d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9f22df3-4c24-431c-9018-73af0e8a313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78bc0a21-d803-4be3-8d10-12d6a3d72d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    words = word_tokenize(sentences[i].lower())  # this will give list of words from each sentence \n",
    "    words = [lemma.lemmatize(word) for word in words if word not in set(stp)]\n",
    "    sentences[i]=' '.join(words)  # convert all the words to sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdd880cf-b443-4ee8-85e4-26707f8818ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['india must stand world .',\n",
       " 'believe unless india stand world , one respect u .',\n",
       " 'strength respect strength .',\n",
       " 'must strong military power also economic power .',\n",
       " 'must go hand-in-hand .',\n",
       " 'good fortune worked three great mind .',\n",
       " 'dr. vikram sarabhai dept .',\n",
       " 'space , professor satish dhawan , succeeded dr. brahm prakash , father nuclear material .',\n",
       " 'lucky worked three closely consider great opportunity life .',\n",
       " 'see four milestone career : twenty year spent isro .',\n",
       " 'given opportunity project director india ’ first satellite launch vehicle , slv3 .',\n",
       " 'one launched rohini .',\n",
       " 'year played important role life scienc .',\n",
       " 'isro year , joined drdo got chance part india ’ guided missile program .',\n",
       " 'second bliss agni met mission requirement 1994 .',\n",
       " 'dept .',\n",
       " 'atomic energy drdo tremendous partnership recent nuclear test , may 11 13 .',\n",
       " 'third bliss .',\n",
       " 'joy participating team nuclear test proving world india make , longer developing nation one .',\n",
       " 'made feel proud indian .',\n",
       " 'fact developed agni re-entry structure , developed new material .',\n",
       " 'light material called carbon-carbon .',\n",
       " 'one day orthopedic surgeon nizam institute medical science visited laboratory .',\n",
       " 'lifted material found light took hospital showed patient .',\n",
       " 'little girl boy heavy metallic caliper weighing three kg .',\n",
       " ', dragging foot around .',\n",
       " 'said : please remove pain patient .',\n",
       " 'three week , made floor reaction orthosis 300-gram caliper took orthopedic center .',\n",
       " 'child ’ believe eye .',\n",
       " 'dragging around three kg .',\n",
       " 'load leg , could move around !',\n",
       " 'parent tear eye .',\n",
       " 'fourth bliss !',\n",
       " 'medium negative ?',\n",
       " 'india embarrassed recognise strength , achievement ?',\n",
       " 'great nation .',\n",
       " 'many amazing success story refuse acknowledge .',\n",
       " 'w']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50deb6e1-943c-436a-aa02-2b7ec7fffcbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
